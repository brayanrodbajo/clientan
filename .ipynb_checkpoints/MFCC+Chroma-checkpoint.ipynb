{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"playlists.csv\", sep=\";\", encoding = \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negatives and positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = data['company'].unique()\n",
    "by_company = [data[data.company == company] for company in companies]\n",
    "positives = []\n",
    "negatives = []\n",
    "for data_com in by_company:\n",
    "    data_com = data_com.sort_values('playlist_sample')\n",
    "    last_pl = int(data_com.tail(1).playlist_sample)\n",
    "    #pls = pd.DataFrame({'pl':range (1,last_pl+1), 'old':[0]*last_pl, 'new':[0]*last_pl})\n",
    "    #curr_pl = data_com.query('playlist_sample == '+str(1))\n",
    "    #pls.new[0]=(curr_pl.shape[0])/3\n",
    "    #sum_pls = [curr_pl.shape[0]/3]\n",
    "    #for i in range(2,last_pl+1):\n",
    "    #    curr_pl = data_com.query('playlist_sample == '+str(i))\n",
    "    #    pre_pl = data_com.query('playlist_sample == '+str(i-1))\n",
    "    #    olds = curr_pl['song'].map(pre_pl['song'].value_counts()).sum(axis = 0)/3\n",
    "    #    pls.old[i-1]= olds/3 \n",
    "    #    pls.new[i-1]=(curr_pl.shape[0]-olds)/3\n",
    "    #    sum_pls.append(curr_pl.shape[0]/3)\n",
    "    #sum_pls = pd.DataFrame(sum_pls)\n",
    "    #pls_rel = (pls[['old']].div(sum_pls.values, axis=0)*100).join(pls[['new']].div(sum_pls.values, axis=0)*100)\n",
    "    #pls[['old','new']].plot(kind='bar', stacked=True, title=data_com.iloc[0,0])\n",
    "    #for n in pls_rel:\n",
    "    #    for i, (cs, ab, pc) in enumerate(zip(pls.iloc[:, 1:].cumsum(1)[n].values, pls[n].values, pls_rel[n].values)):\n",
    "    #        if(pc>0):\n",
    "    #            plt.text(i, cs - ab/2, str(np.round(pc, 1)) + '%', va='center', ha='center')\n",
    "    df_last_pl= data_com.query('playlist_sample == '+str(last_pl))\n",
    "    positives.append(df_last_pl)\n",
    "    pos_loc = pd.DataFrame({}, columns=data_com.columns)\n",
    "    rep=0\n",
    "    for index, row in data_com[data_com.playlist_sample<last_pl].iterrows(): \n",
    "        if not ((df_last_pl['artist'] == row['artist']) & (df_last_pl['song'] ==  row['song'])).any() and pos_loc[(pos_loc['artist']== row['artist']) & (pos_loc['song'] ==  row['song'])].shape[0]<3:\n",
    "            pos_loc= pos_loc.append(row, ignore_index=True)\n",
    "        else:\n",
    "            rep+=1\n",
    "    #n_vs_p = pd.DataFrame({'sam':['pos', 'neg'],'num':[df_last_pl.shape[0]/3,pos_loc.shape[0]/3]})\n",
    "    # n_vs_p.plot.bar(x='sam', y='num', rot=0, title=data_com.iloc[0,0])\n",
    "    negatives.append(pos_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of positives negatives and total by company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arte Francés\n",
      "Negatives:  76.0\n",
      "Positives:  29.0\n",
      "Total:  147.0\n",
      "Club De Banqueros y Empresarios\n",
      "Negatives:  61.0\n",
      "Positives:  24.0\n",
      "Total:  88.0\n",
      "Gramma\n",
      "Negatives:  51.0\n",
      "Positives:  21.0\n",
      "Total:  103.0\n",
      "Hotel Marrakech\n",
      "Negatives:  28.0\n",
      "Positives:  20.0\n",
      "Total:  68.0\n",
      "Specialized\n",
      "Negatives:  38.0\n",
      "Positives:  35.0\n",
      "Total:  103.0\n",
      "Urban Place\n",
      "Negatives:  48.0\n",
      "Positives:  24.0\n",
      "Total:  85.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(companies)):\n",
    "    print(companies[i])\n",
    "    print(\"Negatives: \",negatives[i].shape[0]/3)\n",
    "    print(\"Positives: \",positives[i].shape[0]/3)\n",
    "    print(\"Total: \", by_company[i].shape[0]/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the positives and negatives records with a new column \"chosen\" that takes value of 1 if is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Usuarios\\1144084318\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_n_ps = []\n",
    "for i in range(len(negatives)):\n",
    "    negatives[i]['chosen']=0\n",
    "    positives[i]['chosen']=1\n",
    "    df_n_ps.append(negatives[i].append(positives[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, silhouette_samples, silhouette_score, calinski_harabaz_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 315 entries, 0 to 179\n",
      "Data columns (total 65 columns):\n",
      "company                 315 non-null object\n",
      "playlist_sample         315 non-null object\n",
      "namesfiles              315 non-null object\n",
      "no                      315 non-null object\n",
      "artist                  315 non-null object\n",
      "song                    315 non-null object\n",
      "sampleratefiles         315 non-null object\n",
      "totalsamplesfiles       315 non-null object\n",
      "durationfiles           315 non-null float64\n",
      "bitratefiles            315 non-null float64\n",
      "rmsfiles                315 non-null float64\n",
      "rmsmedianfiles          315 non-null float64\n",
      "lowenergyfiles          315 non-null float64\n",
      "ASRfiles                315 non-null float64\n",
      "beatspectrumfiles       315 non-null float64\n",
      "eventdensityfiles       315 non-null float64\n",
      "tempofiles              315 non-null float64\n",
      "pulseclarityfiles       315 non-null float64\n",
      "zerocrossfiles          315 non-null float64\n",
      "rolloffsfiles           315 non-null float64\n",
      "brightnessfiles         315 non-null float64\n",
      "spreadfiles             315 non-null float64\n",
      "centroidfiles           314 non-null float64\n",
      "kurtosisfiles           315 non-null float64\n",
      "flatnessfiles           315 non-null float64\n",
      "entropyfiles            315 non-null float64\n",
      "mfccfiles_1             315 non-null float64\n",
      "mfccfiles_2             315 non-null float64\n",
      "mfccfiles_3             315 non-null float64\n",
      "mfccfiles_4             315 non-null float64\n",
      "mfccfiles_5             315 non-null float64\n",
      "mfccfiles_6             315 non-null float64\n",
      "mfccfiles_7             315 non-null float64\n",
      "mfccfiles_8             315 non-null float64\n",
      "mfccfiles_9             315 non-null float64\n",
      "mfccfiles_10            315 non-null float64\n",
      "mfccfiles_11            315 non-null float64\n",
      "mfccfiles_12            315 non-null float64\n",
      "mfccfiles_13            315 non-null float64\n",
      "pitchfiles              315 non-null float64\n",
      "inharmonicityfiles      315 non-null float64\n",
      "bestkeyfiles            315 non-null float64\n",
      "keyclarityfiles         315 non-null float64\n",
      "modalityfiles           315 non-null float64\n",
      "tonalcentroidfiles_1    315 non-null float64\n",
      "tonalcentroidfiles_2    315 non-null float64\n",
      "tonalcentroidfiles_3    315 non-null float64\n",
      "tonalcentroidfiles_4    315 non-null float64\n",
      "tonalcentroidfiles_5    315 non-null float64\n",
      "tonalcentroidfiles_6    315 non-null float64\n",
      "chromagramfiles_1       315 non-null float64\n",
      "chromagramfiles_2       315 non-null float64\n",
      "chromagramfiles_3       315 non-null float64\n",
      "chromagramfiles_4       315 non-null float64\n",
      "chromagramfiles_5       315 non-null float64\n",
      "chromagramfiles_6       315 non-null float64\n",
      "chromagramfiles_7       315 non-null float64\n",
      "chromagramfiles_8       315 non-null float64\n",
      "chromagramfiles_9       315 non-null float64\n",
      "chromagramfiles_10      315 non-null float64\n",
      "chromagramfiles_11      315 non-null float64\n",
      "chromagramfiles_12      315 non-null float64\n",
      "attackslopefiles        315 non-null float64\n",
      "attackleapfiles         315 non-null float64\n",
      "chosen                  315 non-null int64\n",
      "dtypes: float64(56), int64(1), object(8)\n",
      "memory usage: 162.4+ KB\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(companies)):\n",
    "    df_n_ps[i].bitratefiles = df_n_ps[i].bitratefiles.astype('float64')\n",
    "    df_n_ps[i].pitchfiles = df_n_ps[i].pitchfiles.astype('float64')\n",
    "    df_n_ps[i].bestkeyfiles = df_n_ps[i].bestkeyfiles.astype('float64')\n",
    "df_n_ps[0].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a reemplazar los NaN y entonces a normalizar los datos para que todas las variables tengan la misma importancia. Solo vamos a considerar los datos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "durationfiles          -1.889141e-16\n",
       "bitratefiles            0.000000e+00\n",
       "rmsfiles                3.559763e-16\n",
       "rmsmedianfiles         -2.396672e-16\n",
       "lowenergyfiles          1.543739e-16\n",
       "ASRfiles                1.226532e-16\n",
       "beatspectrumfiles       2.269789e-16\n",
       "eventdensityfiles      -6.132661e-17\n",
       "tempofiles              4.103860e-16\n",
       "pulseclarityfiles      -6.696583e-17\n",
       "zerocrossfiles         -1.092600e-16\n",
       "rolloffsfiles           2.661011e-16\n",
       "brightnessfiles         1.092600e-16\n",
       "spreadfiles             1.519067e-16\n",
       "centroidfiles           1.501444e-16\n",
       "kurtosisfiles           1.875043e-16\n",
       "flatnessfiles          -4.017950e-17\n",
       "entropyfiles            6.012827e-16\n",
       "mfccfiles_1            -4.398598e-16\n",
       "mfccfiles_2            -2.326182e-17\n",
       "mfccfiles_3             6.308886e-17\n",
       "mfccfiles_4             1.718202e-17\n",
       "mfccfiles_5             1.832749e-17\n",
       "mfccfiles_6            -3.172066e-17\n",
       "mfccfiles_7            -1.400996e-16\n",
       "mfccfiles_8             5.110550e-17\n",
       "mfccfiles_9             3.101575e-17\n",
       "mfccfiles_10           -6.485112e-17\n",
       "mfccfiles_11           -4.229421e-18\n",
       "mfccfiles_12           -1.304071e-17\n",
       "mfccfiles_13           -1.233581e-17\n",
       "pitchfiles              0.000000e+00\n",
       "inharmonicityfiles     -1.009422e-15\n",
       "bestkeyfiles            2.424868e-16\n",
       "keyclarityfiles        -3.972131e-16\n",
       "modalityfiles          -3.771234e-17\n",
       "tonalcentroidfiles_1   -1.517745e-17\n",
       "tonalcentroidfiles_2   -5.921189e-17\n",
       "tonalcentroidfiles_3    2.326182e-17\n",
       "tonalcentroidfiles_4    2.502407e-17\n",
       "tonalcentroidfiles_5    3.260179e-17\n",
       "tonalcentroidfiles_6   -2.361427e-17\n",
       "chromagramfiles_1       6.414622e-17\n",
       "chromagramfiles_2      -2.061843e-17\n",
       "chromagramfiles_3      -3.489272e-17\n",
       "chromagramfiles_4      -1.755210e-16\n",
       "chromagramfiles_5       1.797504e-17\n",
       "chromagramfiles_6      -3.101575e-17\n",
       "chromagramfiles_7      -8.776049e-17\n",
       "chromagramfiles_8       7.471977e-17\n",
       "chromagramfiles_9      -4.194176e-17\n",
       "chromagramfiles_10      3.630253e-17\n",
       "chromagramfiles_11      5.057683e-17\n",
       "chromagramfiles_12     -5.894756e-17\n",
       "attackslopefiles       -6.626093e-17\n",
       "attackleapfiles        -1.423905e-16\n",
       "chosen                  7.218212e-16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_ps_std = [0]*len(companies)\n",
    "for i in range(len(companies)):\n",
    "    df_n_ps[i] = df_n_ps[i].fillna(0)\n",
    "    df_n_ps_std[i] = pd.DataFrame(preprocessing.scale(df_n_ps[i].iloc[:,8:]))\n",
    "    df_n_ps_std[i].columns=df_n_ps[i].columns[8:]\n",
    "df_n_ps_std[0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "durationfiles           1.001591\n",
       "bitratefiles            0.000000\n",
       "rmsfiles                1.001591\n",
       "rmsmedianfiles          1.001591\n",
       "lowenergyfiles          1.001591\n",
       "ASRfiles                1.001591\n",
       "beatspectrumfiles       1.001591\n",
       "eventdensityfiles       1.001591\n",
       "tempofiles              1.001591\n",
       "pulseclarityfiles       1.001591\n",
       "zerocrossfiles          1.001591\n",
       "rolloffsfiles           1.001591\n",
       "brightnessfiles         1.001591\n",
       "spreadfiles             1.001591\n",
       "centroidfiles           1.001591\n",
       "kurtosisfiles           1.001591\n",
       "flatnessfiles           1.001591\n",
       "entropyfiles            1.001591\n",
       "mfccfiles_1             1.001591\n",
       "mfccfiles_2             1.001591\n",
       "mfccfiles_3             1.001591\n",
       "mfccfiles_4             1.001591\n",
       "mfccfiles_5             1.001591\n",
       "mfccfiles_6             1.001591\n",
       "mfccfiles_7             1.001591\n",
       "mfccfiles_8             1.001591\n",
       "mfccfiles_9             1.001591\n",
       "mfccfiles_10            1.001591\n",
       "mfccfiles_11            1.001591\n",
       "mfccfiles_12            1.001591\n",
       "mfccfiles_13            1.001591\n",
       "pitchfiles              0.000000\n",
       "inharmonicityfiles      1.001591\n",
       "bestkeyfiles            1.001591\n",
       "keyclarityfiles         1.001591\n",
       "modalityfiles           1.001591\n",
       "tonalcentroidfiles_1    1.001591\n",
       "tonalcentroidfiles_2    1.001591\n",
       "tonalcentroidfiles_3    1.001591\n",
       "tonalcentroidfiles_4    1.001591\n",
       "tonalcentroidfiles_5    1.001591\n",
       "tonalcentroidfiles_6    1.001591\n",
       "chromagramfiles_1       1.001591\n",
       "chromagramfiles_2       1.001591\n",
       "chromagramfiles_3       1.001591\n",
       "chromagramfiles_4       1.001591\n",
       "chromagramfiles_5       1.001591\n",
       "chromagramfiles_6       1.001591\n",
       "chromagramfiles_7       1.001591\n",
       "chromagramfiles_8       1.001591\n",
       "chromagramfiles_9       1.001591\n",
       "chromagramfiles_10      1.001591\n",
       "chromagramfiles_11      1.001591\n",
       "chromagramfiles_12      1.001591\n",
       "attackslopefiles        1.001591\n",
       "attackleapfiles         1.001591\n",
       "chosen                  1.001591\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_ps_std[0].std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borramos pitch y bitrate porque todos sus valores son 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(companies)):\n",
    "    df_n_ps_std[i] = df_n_ps_std[i].drop(columns=\"pitchfiles\")\n",
    "    df_n_ps_std[i] = df_n_ps_std[i].drop(columns=\"bitratefiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Flatten, Dense, concatenate#, Lambda\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import models, optimizers\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV #permite buscar la mejor configuración de parámetros con C-V\n",
    "from sklearn.metrics import make_scorer # permite crear una clase scorer a partir de una función de score (necesario para el kappa)\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split #metodo de particionamiento de datasets para evaluación\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mfccfiles_1', 'mfccfiles_2', 'mfccfiles_3', 'mfccfiles_4',\n",
       "       'mfccfiles_5', 'mfccfiles_6', 'mfccfiles_7', 'mfccfiles_8',\n",
       "       'mfccfiles_9', 'mfccfiles_10', 'mfccfiles_11', 'mfccfiles_12',\n",
       "       'mfccfiles_13', 'chromagramfiles_1', 'chromagramfiles_2',\n",
       "       'chromagramfiles_3', 'chromagramfiles_4', 'chromagramfiles_5',\n",
       "       'chromagramfiles_6', 'chromagramfiles_7', 'chromagramfiles_8',\n",
       "       'chromagramfiles_9', 'chromagramfiles_10', 'chromagramfiles_11',\n",
       "       'chromagramfiles_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_ps_std[0].columns[17:30].append(df_n_ps_std[0].columns[40:52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 315 entries, 0 to 314\n",
      "Data columns (total 25 columns):\n",
      "mfccfiles_1           315 non-null float64\n",
      "mfccfiles_2           315 non-null float64\n",
      "mfccfiles_3           315 non-null float64\n",
      "mfccfiles_4           315 non-null float64\n",
      "mfccfiles_5           315 non-null float64\n",
      "mfccfiles_6           315 non-null float64\n",
      "mfccfiles_7           315 non-null float64\n",
      "mfccfiles_8           315 non-null float64\n",
      "mfccfiles_9           315 non-null float64\n",
      "mfccfiles_10          315 non-null float64\n",
      "mfccfiles_11          315 non-null float64\n",
      "mfccfiles_12          315 non-null float64\n",
      "mfccfiles_13          315 non-null float64\n",
      "chromagramfiles_1     315 non-null float64\n",
      "chromagramfiles_2     315 non-null float64\n",
      "chromagramfiles_3     315 non-null float64\n",
      "chromagramfiles_4     315 non-null float64\n",
      "chromagramfiles_5     315 non-null float64\n",
      "chromagramfiles_6     315 non-null float64\n",
      "chromagramfiles_7     315 non-null float64\n",
      "chromagramfiles_8     315 non-null float64\n",
      "chromagramfiles_9     315 non-null float64\n",
      "chromagramfiles_10    315 non-null float64\n",
      "chromagramfiles_11    315 non-null float64\n",
      "chromagramfiles_12    315 non-null float64\n",
      "dtypes: float64(25)\n",
      "memory usage: 61.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_n_ps_std_mf_tc = [None]*len(companies)\n",
    "for i in range(len(companies)):\n",
    "    df_n_ps_std_mf_tc[i] = pd.concat([df_n_ps_std[i].iloc[:,17:30], df_n_ps_std[i].iloc[:,40:52]], axis=1)\n",
    "    df_n_ps_std_mf_tc[i].columns=df_n_ps_std[0].columns[17:30].append(df_n_ps_std[0].columns[40:52])\n",
    "df_n_ps_std_mf_tc[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Arte Francés"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mfccfiles_1  mfccfiles_2  mfccfiles_3  mfccfiles_4  mfccfiles_5  \\\n",
      "0     0.297583     1.225637    -0.367641     0.606499     0.072373   \n",
      "1     0.637676    -1.507256    -1.572737    -0.954161    -0.857425   \n",
      "2     2.236730    -0.319414     0.669910    -1.918119    -0.820882   \n",
      "3     0.662077    -0.381499     0.111981    -1.743808    -1.317593   \n",
      "4     0.736502     0.112932    -0.065024    -1.049458    -0.408043   \n",
      "\n",
      "   mfccfiles_6  mfccfiles_7  mfccfiles_8  mfccfiles_9  mfccfiles_10  \\\n",
      "0    -2.029620     0.791469     0.752018     2.268802     -1.383289   \n",
      "1     0.327005     0.816764     0.214245     0.241703      0.637066   \n",
      "2    -2.379333    -1.570021    -2.755344    -2.150610     -2.528577   \n",
      "3    -1.348534    -0.627198    -1.629882    -2.075974     -1.248765   \n",
      "4    -0.437499     0.090831    -0.852983    -1.922491     -0.284365   \n",
      "\n",
      "          ...          chromagramfiles_3  chromagramfiles_4  \\\n",
      "0         ...                   2.143431           0.466379   \n",
      "1         ...                   1.394548          -0.542923   \n",
      "2         ...                  -1.114255           0.326790   \n",
      "3         ...                  -0.672464           0.505231   \n",
      "4         ...                   0.333584           1.122628   \n",
      "\n",
      "   chromagramfiles_5  chromagramfiles_6  chromagramfiles_7  chromagramfiles_8  \\\n",
      "0           2.480688           1.533552          -0.564788          -0.236267   \n",
      "1          -0.194326           0.100084           0.191568           1.691930   \n",
      "2          -1.157732          -1.261521          -1.130503           1.585017   \n",
      "3          -0.830959          -1.046716          -0.912922           1.082754   \n",
      "4           1.139134          -0.481280           0.129896           0.915597   \n",
      "\n",
      "   chromagramfiles_9  chromagramfiles_10  chromagramfiles_11  \\\n",
      "0          -0.737672            0.470152           -0.935468   \n",
      "1          -0.164059            0.599296           -0.175780   \n",
      "2          -1.367743           -1.287569           -0.805298   \n",
      "3          -0.919242           -0.761758           -1.023346   \n",
      "4           0.333032           -0.289806           -0.236639   \n",
      "\n",
      "   chromagramfiles_12  \n",
      "0            0.074931  \n",
      "1            0.267042  \n",
      "2           -1.676436  \n",
      "3           -1.220716  \n",
      "4           -0.281891  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(315, 25)\n",
      "Los parámetros del mejor modelo fueron {'activation': 'tanh', 'hidden_layer_sizes': (30, 30, 30), 'learning_rate_init': 0.009, 'max_iter': 400}, que permiten obtener un Accuracy de 80.51% y un Kappa del 44.52\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                780       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,671\n",
      "Trainable params: 2,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "epochs: 400\n",
      "79/79 [==============================] - 0s 51us/step\n",
      "test loss: 1.2753468751907349, test accuracy: 0.7341772317886353\n",
      "AUC ROC:  0.8026124818577649\n",
      "Kappa:  0.37981308411214953\n",
      "[[44  9]\n",
      " [12 14]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Club De Banqueros y Empresarios"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mfccfiles_1  mfccfiles_2  mfccfiles_3  mfccfiles_4  mfccfiles_5  \\\n",
      "0    -0.339415     0.847773     0.497198    -0.389310     1.225458   \n",
      "1     0.587658    -1.195426     0.636375     0.199876     0.765321   \n",
      "2     1.465595    -2.307943     0.354567    -0.058273    -1.298853   \n",
      "3     0.749403    -1.690498    -0.125200    -1.016135     0.825845   \n",
      "4    -0.280577     0.393332     0.744917     2.411400    -0.777421   \n",
      "\n",
      "   mfccfiles_6  mfccfiles_7  mfccfiles_8  mfccfiles_9  mfccfiles_10  \\\n",
      "0     1.947033    -0.736267     0.492219     0.576682      1.504697   \n",
      "1     0.061181     0.379367    -0.440867     0.232893      1.339920   \n",
      "2    -0.811453    -1.551580    -3.934320    -1.079432      2.546130   \n",
      "3     0.271444    -0.104786    -0.992141     0.049182      1.425948   \n",
      "4    -0.420018     1.258355    -1.544565    -0.498071      0.421527   \n",
      "\n",
      "          ...          chromagramfiles_3  chromagramfiles_4  \\\n",
      "0         ...                  -0.095656          -0.923999   \n",
      "1         ...                  -0.657709          -0.201259   \n",
      "2         ...                   1.959063           0.169276   \n",
      "3         ...                   0.826233          -0.048480   \n",
      "4         ...                  -1.238971          -0.919598   \n",
      "\n",
      "   chromagramfiles_5  chromagramfiles_6  chromagramfiles_7  chromagramfiles_8  \\\n",
      "0          -0.030645          -0.834931          -1.031650          -0.840942   \n",
      "1           1.691433          -0.672783          -0.119944          -0.440080   \n",
      "2          -0.403611          -1.036954           1.447615          -0.340767   \n",
      "3           1.789786          -0.552163           0.121028          -0.111355   \n",
      "4           0.313068          -1.160111           1.316032          -0.700013   \n",
      "\n",
      "   chromagramfiles_9  chromagramfiles_10  chromagramfiles_11  \\\n",
      "0          -0.677716            1.084098           -1.064999   \n",
      "1           0.339906            1.084098            0.504608   \n",
      "2          -0.846170           -0.515065           -0.699878   \n",
      "3           0.220614            1.084098            0.073241   \n",
      "4          -1.600210            1.084098           -1.072155   \n",
      "\n",
      "   chromagramfiles_12  \n",
      "0           -1.156623  \n",
      "1            0.931676  \n",
      "2            0.032355  \n",
      "3            1.176257  \n",
      "4            1.270095  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(255, 25)\n",
      "Los parámetros del mejor modelo fueron {'activation': 'tanh', 'hidden_layer_sizes': (30, 30, 30), 'learning_rate_init': 0.01, 'max_iter': 200}, que permiten obtener un Accuracy de 82.20% y un Kappa del 55.02\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                780       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,671\n",
      "Trainable params: 2,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "epochs: 200\n",
      "64/64 [==============================] - 0s 31us/step\n",
      "test loss: 0.5524450540542603, test accuracy: 0.875\n",
      "AUC ROC:  0.9009661835748792\n",
      "Kappa:  0.6799999999999999\n",
      "[[43  3]\n",
      " [ 5 13]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Gramma"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mfccfiles_1  mfccfiles_2  mfccfiles_3  mfccfiles_4  mfccfiles_5  \\\n",
      "0    -0.674917     0.169246     0.673543     1.157142    -0.633186   \n",
      "1     0.277269     0.514176     0.200398     0.988939    -1.756594   \n",
      "2     1.483921     0.724793     0.473099     0.439577    -0.358096   \n",
      "3    -0.734008    -0.683844    -0.764866    -0.225060    -0.261235   \n",
      "4    -0.834815    -0.735908    -1.177596    -0.093532     0.508050   \n",
      "\n",
      "   mfccfiles_6  mfccfiles_7  mfccfiles_8  mfccfiles_9  mfccfiles_10  \\\n",
      "0     0.688145     0.215883    -0.452048     1.101066      0.064017   \n",
      "1    -0.022788    -0.235704     0.523508    -0.604231      1.188209   \n",
      "2    -0.452581    -0.213173    -0.596057    -0.767473      0.696227   \n",
      "3    -0.243429     0.588768     0.874148     1.302526      0.091256   \n",
      "4     0.503458     1.380798     1.847226     1.227896      0.017729   \n",
      "\n",
      "          ...          chromagramfiles_3  chromagramfiles_4  \\\n",
      "0         ...                  -0.741425          -0.871269   \n",
      "1         ...                   0.055411          -0.561004   \n",
      "2         ...                  -0.304151           2.056775   \n",
      "3         ...                  -0.601072           1.282246   \n",
      "4         ...                   1.366350           0.941326   \n",
      "\n",
      "   chromagramfiles_5  chromagramfiles_6  chromagramfiles_7  chromagramfiles_8  \\\n",
      "0           0.189298          -0.623423          -0.529336           0.357204   \n",
      "1           0.495091          -0.306711           0.886175          -0.561042   \n",
      "2          -0.998633          -0.428416           1.821160          -1.229826   \n",
      "3          -0.578812          -0.045810           1.094766           0.365693   \n",
      "4          -0.898589          -0.324641           1.117103           0.022453   \n",
      "\n",
      "   chromagramfiles_9  chromagramfiles_10  chromagramfiles_11  \\\n",
      "0          -0.325100            0.746582           -0.476439   \n",
      "1           1.431598            0.158038            0.235945   \n",
      "2          -0.732612           -1.686385           -0.297109   \n",
      "3           1.431598           -0.618841            0.417565   \n",
      "4           1.431598           -0.507270            0.477771   \n",
      "\n",
      "   chromagramfiles_12  \n",
      "0            0.217416  \n",
      "1            1.435645  \n",
      "2            0.515440  \n",
      "3            0.135593  \n",
      "4           -0.297988  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(216, 25)\n",
      "Los parámetros del mejor modelo fueron {'activation': 'logistic', 'hidden_layer_sizes': (10, 10), 'learning_rate_init': 0.02, 'max_iter': 200}, que permiten obtener un Accuracy de 75.31% y un Kappa del 20.67\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 381\n",
      "Trainable params: 381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "epochs: 200\n",
      "54/54 [==============================] - 0s 56us/step\n",
      "test loss: 0.6173999199160823, test accuracy: 0.6666666865348816\n",
      "AUC ROC:  0.7074721780604134\n",
      "Kappa:  0.17487266553480474\n",
      "[[30  7]\n",
      " [11  6]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Hotel Marrakech"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mfccfiles_1  mfccfiles_2  mfccfiles_3  mfccfiles_4  mfccfiles_5  \\\n",
      "0     0.221235     1.617887     0.929874    -0.231486    -0.525862   \n",
      "1     0.836735    -0.529605    -1.268139    -0.791053     0.815880   \n",
      "2    -0.190995     1.202756     0.050028    -2.631154     3.701544   \n",
      "3     0.521202     1.354284     1.423683    -0.634173     0.934734   \n",
      "4     0.250234     1.586078    -1.791096     0.127156     1.573000   \n",
      "\n",
      "   mfccfiles_6  mfccfiles_7  mfccfiles_8  mfccfiles_9  mfccfiles_10  \\\n",
      "0     1.384826     0.709441     0.512679    -2.231286     -2.278872   \n",
      "1    -1.992230    -0.371430    -0.356669     1.323871      0.946394   \n",
      "2    -1.158173     0.439586     2.317548    -2.282526     -1.571775   \n",
      "3     0.214772    -0.349135     1.009101    -2.193012     -0.301254   \n",
      "4     0.288525     1.962471     1.500627     1.352853     -1.921935   \n",
      "\n",
      "          ...          chromagramfiles_3  chromagramfiles_4  \\\n",
      "0         ...                   0.508438           0.658218   \n",
      "1         ...                   1.708314           0.223308   \n",
      "2         ...                  -1.227033          -0.981611   \n",
      "3         ...                  -1.073758          -0.208557   \n",
      "4         ...                  -1.227033          -0.725200   \n",
      "\n",
      "   chromagramfiles_5  chromagramfiles_6  chromagramfiles_7  chromagramfiles_8  \\\n",
      "0           1.668751          -0.289029          -0.581158           1.476860   \n",
      "1           0.928680          -0.795001           0.621735          -0.834425   \n",
      "2          -1.054713          -1.027505          -0.745868           0.198884   \n",
      "3           0.002105          -0.655399          -0.056661          -1.206025   \n",
      "4          -1.112673          -0.992824          -0.809889          -1.428072   \n",
      "\n",
      "   chromagramfiles_9  chromagramfiles_10  chromagramfiles_11  \\\n",
      "0           0.248923            1.428276           -0.870636   \n",
      "1          -0.922785           -0.428866           -1.169994   \n",
      "2           0.508413           -1.114895           -0.312476   \n",
      "3          -1.133355           -1.217881           -0.812411   \n",
      "4          -1.315307           -1.379943           -0.903603   \n",
      "\n",
      "   chromagramfiles_12  \n",
      "0           -0.174217  \n",
      "1           -0.427540  \n",
      "2            1.844563  \n",
      "3            1.844563  \n",
      "4            1.844563  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(144, 25)\n",
      "Los parámetros del mejor modelo fueron {'activation': 'relu', 'hidden_layer_sizes': (20, 10), 'learning_rate_init': 0.005, 'max_iter': 400}, que permiten obtener un Accuracy de 78.70% y un Kappa del 56.97\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 741\n",
      "Trainable params: 741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "epochs: 400\n",
      "36/36 [==============================] - 0s 55us/step\n",
      "test loss: 0.2423683206240336, test accuracy: 0.8888888955116272\n",
      "AUC ROC:  0.9642857142857142\n",
      "Kappa:  0.76\n",
      "[[21  1]\n",
      " [ 3 11]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Specialized"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mfccfiles_1  mfccfiles_2  mfccfiles_3  mfccfiles_4  mfccfiles_5  \\\n",
      "0     0.992062    -0.477172    -1.079451    -2.369470    -1.705431   \n",
      "1     0.843575    -0.507672    -0.731713    -0.334904     1.442336   \n",
      "2     0.816922    -0.263544     0.639646    -0.865417     1.276602   \n",
      "3     4.368525     0.851784    -0.671158    -0.128467     2.141169   \n",
      "4     0.001312     0.535305    -0.648296     0.221414     0.549478   \n",
      "\n",
      "   mfccfiles_6  mfccfiles_7  mfccfiles_8  mfccfiles_9  mfccfiles_10  \\\n",
      "0    -0.098594    -0.281836    -1.432001    -0.898623      0.130446   \n",
      "1    -0.491141    -0.266416    -0.511246     1.004414      0.558777   \n",
      "2    -0.245238     0.106722    -0.761365    -0.170481     -1.443667   \n",
      "3    -0.472725    -1.437233    -1.858760     1.581800     -0.145852   \n",
      "4     0.736878    -0.439538    -0.138787     0.584258      0.095671   \n",
      "\n",
      "          ...          chromagramfiles_3  chromagramfiles_4  \\\n",
      "0         ...                  -0.348132           2.966304   \n",
      "1         ...                   0.041297          -0.917052   \n",
      "2         ...                   0.613536          -0.978644   \n",
      "3         ...                  -0.365668           0.759057   \n",
      "4         ...                   0.508800           0.525847   \n",
      "\n",
      "   chromagramfiles_5  chromagramfiles_6  chromagramfiles_7  chromagramfiles_8  \\\n",
      "0          -0.925235           0.552064          -0.710296           0.412009   \n",
      "1           0.656635          -1.022407          -0.805166          -0.905135   \n",
      "2           0.836157          -0.735689          -0.059767          -1.571350   \n",
      "3          -1.136519          -0.071939          -0.412587          -1.310708   \n",
      "4           0.506842          -0.390517          -0.241209          -0.409725   \n",
      "\n",
      "   chromagramfiles_9  chromagramfiles_10  chromagramfiles_11  \\\n",
      "0          -0.784684           -1.667162           -0.834151   \n",
      "1          -0.708805            1.299875           -0.948816   \n",
      "2           1.278264           -1.103616           -1.153426   \n",
      "3           1.465231           -1.266573            0.040076   \n",
      "4           1.465231           -0.148455           -0.354779   \n",
      "\n",
      "   chromagramfiles_12  \n",
      "0           -1.566379  \n",
      "1           -1.413196  \n",
      "2            0.685062  \n",
      "3           -0.308065  \n",
      "4            0.188297  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(219, 25)\n",
      "Los parámetros del mejor modelo fueron {'activation': 'relu', 'hidden_layer_sizes': (30, 30), 'learning_rate_init': 0.008, 'max_iter': 400}, que permiten obtener un Accuracy de 75.61% y un Kappa del 51.22\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 30)                780       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 1,741\n",
      "Trainable params: 1,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "epochs: 400\n",
      "55/55 [==============================] - 0s 36us/step\n",
      "test loss: 1.5191197005185213, test accuracy: 0.6181818246841431\n",
      "AUC ROC:  0.6653333333333332\n",
      "Kappa:  0.2524271844660195\n",
      "[[15 15]\n",
      " [ 6 19]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Urban Place"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mfccfiles_1  mfccfiles_2  mfccfiles_3  mfccfiles_4  mfccfiles_5  \\\n",
      "0    -1.420085    -0.330086     0.476982     0.852458    -0.881089   \n",
      "1    -0.288523    -1.545259    -1.137074     1.113906     0.311278   \n",
      "2    -0.424115     0.410085     0.838888     0.219947    -0.375953   \n",
      "3    -0.436131    -1.584784     0.658995     0.766397    -1.275956   \n",
      "4     0.000543     0.507984    -0.978397    -0.501031     0.347848   \n",
      "\n",
      "   mfccfiles_6  mfccfiles_7  mfccfiles_8  mfccfiles_9  mfccfiles_10  \\\n",
      "0    -0.037777    -0.607746    -0.070107    -0.654790     -0.418599   \n",
      "1    -1.566031    -2.038457    -0.322607    -0.291288      1.094837   \n",
      "2    -0.789691    -0.335746    -0.306896    -0.962051      0.861800   \n",
      "3     1.369786     1.180080    -2.004124    -0.366360      0.460536   \n",
      "4     0.605158     0.571957    -0.261476     0.046623     -0.176286   \n",
      "\n",
      "          ...          chromagramfiles_3  chromagramfiles_4  \\\n",
      "0         ...                   2.211117          -0.229901   \n",
      "1         ...                  -0.417753           1.148299   \n",
      "2         ...                   0.141778           1.742806   \n",
      "3         ...                  -1.159142          -0.779634   \n",
      "4         ...                  -0.936463          -0.072578   \n",
      "\n",
      "   chromagramfiles_5  chromagramfiles_6  chromagramfiles_7  chromagramfiles_8  \\\n",
      "0           0.645559          -0.393204           0.424372          -0.229283   \n",
      "1           1.047397          -0.025553           0.529401          -0.322715   \n",
      "2           0.991984           0.907397           1.476307           0.831252   \n",
      "3          -1.287956          -1.177352          -1.012282           0.555960   \n",
      "4          -1.082182          -0.957161          -1.022927          -0.233777   \n",
      "\n",
      "   chromagramfiles_9  chromagramfiles_10  chromagramfiles_11  \\\n",
      "0          -0.693774            1.147599           -0.220378   \n",
      "1           0.788981           -0.702420           -0.209698   \n",
      "2           1.523918            0.670640           -0.046392   \n",
      "3           1.314559            0.253537            1.699829   \n",
      "4           0.259301           -0.358189            1.699829   \n",
      "\n",
      "   chromagramfiles_12  \n",
      "0            0.262481  \n",
      "1            1.924655  \n",
      "2            0.497913  \n",
      "3           -1.383790  \n",
      "4           -0.811341  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(216, 25)\n",
      "Los parámetros del mejor modelo fueron {'activation': 'relu', 'hidden_layer_sizes': (30, 20, 10), 'learning_rate_init': 0.004, 'max_iter': 200}, que permiten obtener un Accuracy de 79.63% y un Kappa del 55.20\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 30)                780       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,621\n",
      "Trainable params: 1,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "epochs: 200\n",
      "54/54 [==============================] - 0s 37us/step\n",
      "test loss: 0.8880829391656099, test accuracy: 0.6481481194496155\n",
      "AUC ROC:  0.7039473684210525\n",
      "Kappa:  0.2262443438914028\n",
      "[[26 12]\n",
      " [ 7  9]]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "for comp in range(len(companies)):\n",
    "    title = '## '+companies[comp]\n",
    "    display(Markdown(title))\n",
    "    \n",
    "    X = df_n_ps_std_mf_tc[comp]\n",
    "    y = df_n_ps[comp]['chosen']\n",
    "    \n",
    "\n",
    "    print(X.head())\n",
    "    print(X.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "\n",
    "    activation_vec = ['logistic', 'relu', 'tanh']\n",
    "    max_iter_vec = [10, 20, 50, 75, 100, 200, 300, 400, 500, 1000, 2000]\n",
    "    hidden_layer_sizes_vec = [(10,), (20,), (30,), (10, 10), (20, 20), (30, 30), (20, 10), \n",
    "                              (10, 10, 10), (20, 20, 20), (30, 30, 30), (30, 20, 10)]\n",
    "    learning_rate_init_vec = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02]\n",
    "    batch_size_vec = [10, 20, 40, 60, 80, 100, 150]\n",
    "\n",
    "\n",
    "    np.random.seed(1234)\n",
    "    parametros = {'activation': activation_vec,\n",
    "                  'max_iter':max_iter_vec,\n",
    "                  'hidden_layer_sizes': hidden_layer_sizes_vec,\n",
    "                  'learning_rate_init': learning_rate_init_vec#,\n",
    "                  #'batch_size': batch_size_vec\n",
    "                  }\n",
    "    scoring = {'kappa':make_scorer(cohen_kappa_score), 'accuracy':'accuracy'}\n",
    "    grid = GridSearchCV(mlp, param_grid=parametros, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1, iid=True)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Los parámetros del mejor modelo fueron {0}, que permiten obtener un Accuracy de {1:.2f}% y un Kappa del {2:.2f}\".format(\n",
    "        grid.best_params_, grid.best_score_*100, grid.cv_results_['mean_test_kappa'][grid.best_index_]*100))\n",
    "\n",
    "    n0=X_train.shape[1]\n",
    "    ### hidden_layer_sizes\n",
    "    ns = []\n",
    "    for i in range (len(grid.best_params_['hidden_layer_sizes'])):\n",
    "        ns.append(grid.best_params_['hidden_layer_sizes'][i])\n",
    "\n",
    "    ns.append(1)\n",
    "    lr = grid.best_params_['learning_rate_init']\n",
    "    epochs = grid.best_params_['max_iter']\n",
    "\n",
    "    input_tensor = Input(shape = (n0,))\n",
    "    hidden_outputs = [input_tensor]\n",
    "    if grid.best_params_['activation'] == 'logistic':\n",
    "        grid.best_params_['activation'] = 'sigmoid'\n",
    "    for i in range (len(ns)-1):\n",
    "        hidden_outputs.append(Dense(ns[i], activation = grid.best_params_['activation'])(hidden_outputs[i]))\n",
    "    classification_output = Dense(ns[-1], activation = 'sigmoid')(hidden_outputs[-1])\n",
    "\n",
    "    model = Model([input_tensor], [classification_output])\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.set_weights(weights)\n",
    "    adam = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=0, \n",
    "                callbacks=[\n",
    "                    keras.callbacks.ReduceLROnPlateau(\n",
    "                        monitor='val_accuracy', factor=0.5, patience=10, min_delta=0.01, verbose=0\n",
    "                    )\n",
    "                ]\n",
    "             )\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    print(\"epochs: \"+str(len(acc)))\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(\"test loss: {}, test accuracy: {}\".format(test_loss, test_acc))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"AUC ROC: \",roc_auc_score(y_test, y_pred))\n",
    "\n",
    "    y_pred = list(map(lambda i: int(i>=0.5), y_pred))\n",
    "    print(\"Kappa: \",cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mfccfiles_1', 'mfccfiles_2', 'mfccfiles_3', 'mfccfiles_4',\n",
       "       'mfccfiles_5', 'mfccfiles_6', 'mfccfiles_7', 'mfccfiles_8',\n",
       "       'mfccfiles_9', 'mfccfiles_10', 'mfccfiles_11', 'mfccfiles_12',\n",
       "       'mfccfiles_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_ps_std[0].columns[17:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 315 entries, 0 to 314\n",
      "Data columns (total 13 columns):\n",
      "mfccfiles_1     315 non-null float64\n",
      "mfccfiles_2     315 non-null float64\n",
      "mfccfiles_3     315 non-null float64\n",
      "mfccfiles_4     315 non-null float64\n",
      "mfccfiles_5     315 non-null float64\n",
      "mfccfiles_6     315 non-null float64\n",
      "mfccfiles_7     315 non-null float64\n",
      "mfccfiles_8     315 non-null float64\n",
      "mfccfiles_9     315 non-null float64\n",
      "mfccfiles_10    315 non-null float64\n",
      "mfccfiles_11    315 non-null float64\n",
      "mfccfiles_12    315 non-null float64\n",
      "mfccfiles_13    315 non-null float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 32.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_n_ps_std_mfcc = [None]*len(companies)\n",
    "for i in range(len(companies)):\n",
    "    df_n_ps_std_mfcc[i] = pd.DataFrame(df_n_ps_std[i].iloc[:,17:30])\n",
    "    df_n_ps_std_mfcc[i].columns=df_n_ps_std[i].columns[17:30]\n",
    "df_n_ps_std_mfcc[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chromagramfiles_1', 'chromagramfiles_2', 'chromagramfiles_3',\n",
       "       'chromagramfiles_4', 'chromagramfiles_5', 'chromagramfiles_6',\n",
       "       'chromagramfiles_7', 'chromagramfiles_8', 'chromagramfiles_9',\n",
       "       'chromagramfiles_10', 'chromagramfiles_11', 'chromagramfiles_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_ps_std[0].columns[40:52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 315 entries, 0 to 314\n",
      "Data columns (total 12 columns):\n",
      "chromagramfiles_1     315 non-null float64\n",
      "chromagramfiles_2     315 non-null float64\n",
      "chromagramfiles_3     315 non-null float64\n",
      "chromagramfiles_4     315 non-null float64\n",
      "chromagramfiles_5     315 non-null float64\n",
      "chromagramfiles_6     315 non-null float64\n",
      "chromagramfiles_7     315 non-null float64\n",
      "chromagramfiles_8     315 non-null float64\n",
      "chromagramfiles_9     315 non-null float64\n",
      "chromagramfiles_10    315 non-null float64\n",
      "chromagramfiles_11    315 non-null float64\n",
      "chromagramfiles_12    315 non-null float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 29.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_n_ps_std_ch = [None]*len(companies)\n",
    "for i in range(len(companies)):\n",
    "    df_n_ps_std_ch[i] = pd.DataFrame(df_n_ps_std[i].iloc[:,40:52])\n",
    "    df_n_ps_std_ch[i].columns=df_n_ps_std[i].columns[40:52]\n",
    "df_n_ps_std_ch[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_best_params= [\n",
    "    [{'activation': 'sigmoid', 'hidden_layer_sizes': (30,), 'learning_rate_init': 0.003, 'max_iter': 2000}, {'activation': 'tanh', 'hidden_layer_sizes': (30, 30), 'learning_rate_init': 0.003, 'max_iter': 200}], \n",
    "    [{'activation': 'relu', 'hidden_layer_sizes': (20, 20, 20), 'learning_rate_init': 0.009, 'max_iter': 300}, {'activation': 'tanh', 'hidden_layer_sizes': (10, 10), 'learning_rate_init': 0.003, 'max_iter': 200}],\n",
    "    [{'activation': 'relu', 'hidden_layer_sizes': (30, 30, 30), 'learning_rate_init': 0.007, 'max_iter': 10}, {'activation': 'relu', 'hidden_layer_sizes': (30, 30), 'learning_rate_init': 0.006, 'max_iter': 20}],\n",
    "    [{'activation': 'relu', 'hidden_layer_sizes': (20, 10), 'learning_rate_init': 0.004, 'max_iter': 100}, {'activation': 'tanh', 'hidden_layer_sizes': (30,), 'learning_rate_init': 0.001, 'max_iter': 1000}],\n",
    "    [{'activation': 'tanh', 'hidden_layer_sizes': (30,), 'learning_rate_init': 0.008, 'max_iter': 300}, {'activation': 'sigmoid', 'hidden_layer_sizes': (20,), 'learning_rate_init': 0.004, 'max_iter': 2000}],\n",
    "    [{'activation': 'sigmoid', 'hidden_layer_sizes': (30, 30), 'learning_rate_init': 0.009, 'max_iter': 1000}, {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'learning_rate_init': 0.006, 'max_iter': 200}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Arte Francés"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 13)\n",
      "(236, 1)\n",
      "(315, 12)\n",
      "(236, 1)\n",
      "AUC ROC:  0.8055555555555556\n",
      "Kappa:  0.6859315589353612\n",
      "[[41  0]\n",
      " [ 7 11]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Club De Banqueros y Empresarios"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 13)\n",
      "(191, 1)\n",
      "(255, 12)\n",
      "(191, 1)\n",
      "AUC ROC:  0.5833333333333334\n",
      "Kappa:  0.2592592592592593\n",
      "[[42  0]\n",
      " [ 5  1]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Gramma"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 13)\n",
      "(162, 1)\n",
      "(216, 12)\n",
      "(162, 1)\n",
      "AUC ROC:  0.63625\n",
      "Kappa:  0.3070422535211267\n",
      "[[24  1]\n",
      " [11  5]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Hotel Marrakech"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 13)\n",
      "(108, 1)\n",
      "(144, 12)\n",
      "(108, 1)\n",
      "AUC ROC:  0.5416666666666666\n",
      "Kappa:  0.09174311926605505\n",
      "[[15  0]\n",
      " [11  1]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Specialized"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 13)\n",
      "(164, 1)\n",
      "(219, 12)\n",
      "(164, 1)\n",
      "AUC ROC:  0.5849282296650717\n",
      "Kappa:  0.16924910607866517\n",
      "[[13  9]\n",
      " [ 8 11]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Urban Place"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 13)\n",
      "(162, 1)\n",
      "(216, 12)\n",
      "(162, 1)\n",
      "AUC ROC:  0.8558201058201057\n",
      "Kappa:  0.7240915208613727\n",
      "[[25  2]\n",
      " [ 3 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.display import display, Markdown, Latex\n",
    "for comp in range(len(companies)):\n",
    "    title = '## '+companies[comp]\n",
    "    display(Markdown(title))\n",
    "\n",
    "    X = df_n_ps_std_mfcc[comp]\n",
    "    y = df_n_ps[comp]['chosen']\n",
    "    print(X.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    grid_best_params_=all_best_params[comp][0]\n",
    "    n0=13\n",
    "    ### hidden_layer_sizes\n",
    "    ns = []\n",
    "    for i in range (len(grid_best_params_['hidden_layer_sizes'])):\n",
    "        ns.append(grid_best_params_['hidden_layer_sizes'][i])\n",
    "\n",
    "    ns.append(1)\n",
    "    lr = grid_best_params_['learning_rate_init']\n",
    "    epochs = grid_best_params_['max_iter']\n",
    "\n",
    "    input_tensor = Input(shape = (n0,))\n",
    "    hidden_outputs = [input_tensor]\n",
    "    for i in range (len(ns)-1):\n",
    "        hidden_outputs.append(Dense(ns[i], activation = grid_best_params_['activation'])(hidden_outputs[i]))\n",
    "    classification_output = Dense(ns[-1], activation = 'sigmoid')(hidden_outputs[-1])\n",
    "\n",
    "    model = Model([input_tensor], [classification_output])\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    model.set_weights(weights)\n",
    "    adam = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=0,\n",
    "                callbacks=[\n",
    "                    keras.callbacks.ReduceLROnPlateau(\n",
    "                        monitor='val_accuracy', factor=0.5, patience=10, min_delta=0.01, verbose=0\n",
    "                    )\n",
    "                ]\n",
    "             )\n",
    "    y_prob_mfcc = model.predict(X_train)\n",
    "\n",
    "    print(y_prob_mfcc.shape)\n",
    "\n",
    "    ## CHROMAGAMS\n",
    "    X = df_n_ps_std_ch[comp]\n",
    "    y = df_n_ps[comp]['chosen']\n",
    "    print(X.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    grid_best_params_=all_best_params[comp][1]\n",
    "    n0=12\n",
    "    ### hidden_layer_sizes\n",
    "    ns = []\n",
    "    for i in range (len(grid_best_params_['hidden_layer_sizes'])):\n",
    "        ns.append(grid_best_params_['hidden_layer_sizes'][i])\n",
    "\n",
    "    ns.append(1)\n",
    "    lr = grid_best_params_['learning_rate_init']\n",
    "    epochs = grid_best_params_['max_iter']\n",
    "\n",
    "    input_tensor = Input(shape = (n0,))\n",
    "    hidden_outputs = [input_tensor]\n",
    "    for i in range (len(ns)-1):\n",
    "        hidden_outputs.append(Dense(ns[i], activation = grid_best_params_['activation'])(hidden_outputs[i]))\n",
    "    classification_output = Dense(ns[-1], activation = 'sigmoid')(hidden_outputs[-1])\n",
    "\n",
    "    model = Model([input_tensor], [classification_output])\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    model.set_weights(weights)\n",
    "    adam = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=0,\n",
    "                callbacks=[\n",
    "                    keras.callbacks.ReduceLROnPlateau(\n",
    "                        monitor='val_accuracy', factor=0.5, patience=10, min_delta=0.01, verbose=0\n",
    "                    )\n",
    "                ]\n",
    "             )\n",
    "    y_prob_ch = model.predict(X_train)\n",
    "\n",
    "    print(y_prob_ch.shape)\n",
    "\n",
    "\n",
    "\n",
    "    X = np.concatenate((y_prob_mfcc, y_prob_ch), axis=1)\n",
    "\n",
    "    y  = y_train.values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train, y_train)\n",
    "    y_pred = LR.predict(X_test)\n",
    "\n",
    "    print(\"AUC ROC: \",roc_auc_score(y_test, y_pred))\n",
    "    y_pred = list(map(lambda i: int(i>=0.5), y_pred))\n",
    "    print(\"Kappa: \",cohen_kappa_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC:  0.8895686887095374\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
